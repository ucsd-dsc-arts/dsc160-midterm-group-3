{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hcD2nPQvPOFM"
   },
   "source": [
    "# Generating Beyonce Lyrics using an RNN text generation model\n",
    "\n",
    "(adapted from the [tensorflow example](https://www.tensorflow.org/tutorials/sequences/text_generation), to run on [datahub.ucsd.edu](datahub.ucsd.edu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yG_n40gFzf9s"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from IPython.display import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening the txt file and examining the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pD_55cOxLkAb"
   },
   "outputs": [],
   "source": [
    "path_to_file = \"lyrics_text.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aavnuByVymwK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 272892 characters\n"
     ]
    }
   ],
   "source": [
    "#open the file and read it \n",
    "text = open(path_to_file, 'rb').read().decode(encoding = \"ISO-8859-1\")\n",
    "# length of text\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IlCgQBRVymwR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 unique characters\n"
     ]
    }
   ],
   "source": [
    "# Number of unique characters \n",
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rNnrKn_lL-IJ"
   },
   "source": [
    "## Process the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LFjSVAlWzf-N"
   },
   "source": [
    "## Vectorize the text\n",
    "\n",
    "Mapping strings to numerical representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IalZLbvOzf-F"
   },
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l1VKcQHcymwb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'head down as ' ---- characters mapped to int ---- > [34 31 27 30  0 30 41 49 40  0 27 45  0]\n"
     ]
    }
   ],
   "source": [
    "# Example of the character mapping\n",
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bbmsf23Bymwe"
   },
   "source": [
    "## Prediction\n",
    "\n",
    "Creating the training examples and targets in order to use them for prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0UHJDA39zf-O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n",
      "e\n",
      "a\n",
      "d\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//seq_length\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l4hkDU3i7ozi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'head down as i watch my feet take turns hitting the ground eyes shut i find myself in love racing the'\n",
      "' earth and im soaked in your love and love was right in my path, in my grasp and me and you belong  i'\n",
      "' wanna run (run) smash into you i wanna run (run) and smash into you  ears closed what i hear no one '\n",
      "'else has to know cause i know that what we have is worth first place in gold and im soaked in your lo'\n",
      "'ve and love is right in my path, in my grasp and me and you belong, oh...  i wanna run (run) smash in'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9NGu-FkO_kYU"
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GNbw-iR0ymwj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'head down as i watch my feet take turns hitting the ground eyes shut i find myself in love racing th'\n",
      "Target data: 'ead down as i watch my feet take turns hitting the ground eyes shut i find myself in love racing the'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "    print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0eBu9WZG84i0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 34 ('h')\n",
      "  expected output: 31 ('e')\n",
      "Step    1\n",
      "  input: 31 ('e')\n",
      "  expected output: 27 ('a')\n",
      "Step    2\n",
      "  input: 27 ('a')\n",
      "  expected output: 30 ('d')\n",
      "Step    3\n",
      "  input: 30 ('d')\n",
      "  expected output: 0 (' ')\n",
      "Step    4\n",
      "  input: 0 (' ')\n",
      "  expected output: 30 ('d')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MJdfPmdqzf-R"
   },
   "source": [
    "## Training batches\n",
    "\n",
    "Splitting the text into mangeable sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2pGotuNzf-S"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = examples_per_epoch//BATCH_SIZE\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r6oUuElIMgVx"
   },
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHT8cLh7EAsg"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wjKZrC39ELy0"
   },
   "outputs": [],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "    rnn = tf.keras.layers.CuDNNGRU\n",
    "    rnn2 = tf.keras.layers.CuDNNGRU\n",
    "else:\n",
    "    import functools\n",
    "    rnn = functools.partial(\n",
    "    tf.keras.layers.GRU, recurrent_activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MtCrdfzEI2N0"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, \n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    rnn(rnn_units,\n",
    "        return_sequences=True, \n",
    "        recurrent_initializer='glorot_uniform',\n",
    "        stateful=True),\n",
    "\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wwsrpOik5zhv"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab), \n",
    "  embedding_dim=embedding_dim, \n",
    "  rnn_units=rnn_units, \n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ubPo0_9Prjb"
   },
   "source": [
    "## Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C-_70kKAPrPU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 78) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1): \n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vPGmAAXmVLGC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (64, None, 256)           19968     \n",
      "_________________________________________________________________\n",
      "cu_dnngru_4 (CuDNNGRU)       (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (64, None, 78)            79950     \n",
      "=================================================================\n",
      "Total params: 4,038,222\n",
      "Trainable params: 4,038,222\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uwv0gEkURfx1"
   },
   "source": [
    "### sampling from the output distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4V4MfFg0RQJg"
   },
   "outputs": [],
   "source": [
    "# sampled_indices = tf.random.multinomial(example_batch_predictions[0], num_samples=1) # TF 1.12\n",
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YqFMUQc_UFgM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  0,  9, 32, 68, 51, 62, 64, 43, 63,  4, 45, 63, 73, 20, 49, 18,\n",
       "       23, 20, 52,  7, 42, 65, 59, 18, 65, 69, 61, 16, 59,  7, 12, 63, 64,\n",
       "       39,  5, 67, 71, 32, 69, 28, 73, 28, 48, 11, 33, 36, 35, 27, 73, 59,\n",
       "        1, 17,  9, 30, 47, 49, 33, 55, 16, 65, 71, 63, 55,  7, 33, 34, 25,\n",
       "       46,  3, 74, 63,  9, 15, 43, 39, 44, 26,  3, 46, 16, 15, 22, 63, 12,\n",
       "       71, 51, 50, 16, 37, 56, 44, 48, 73, 54, 42,  7, 36, 54, 31])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xWcFwPwLSo05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " ' that you my heart aint no chance you could fight that the summertime, when you hot baby take that, '\n",
      "\n",
      "Next Char Predictions: \n",
      " '! .f¨y\\x9d¢q¡(s¡³9w7?9z,p£\\x987£©\\x9c5\\x98,1¡¢m)§¯f©b³bv0gjia³\\x98!6.duwg\\x805£¯¡\\x80,gh]t&º¡.4qmr`&t54;¡1¯yx5k\\x89rv³}p,j}e'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LJL0Q0YPY6Ee"
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UAjbjY03eiQ4"
   },
   "source": [
    "### Use an optimizer and a loss function to improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4HrXTACTdzY-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 78)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.3562894\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\") \n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DDl1_Een6rL0"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.train.AdamOptimizer(),\n",
    "    loss = loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ieSJdchZggUj"
   },
   "source": [
    "### Configure checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6fWTriUZP-n"
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training'\n",
    "\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Ky3F_BhgkTW"
   },
   "source": [
    "### Execute the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yGBE2zxMMHs"
   },
   "outputs": [],
   "source": [
    "EPOCHS=30 #10, 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UK-hmKjYVoll",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 3.5802\n",
      "Epoch 2/30\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.4782\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2630\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.1347\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.0179\n",
      "Epoch 6/30\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.9097WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.global_step\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.optimizer.beta1_power\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.optimizer.beta2_power\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.optimizer's state 'm' for (root).layer_with_weights-1.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.optimizer's state 'v' for (root).layer_with_weights-1.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 1.9087\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.8095\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.7108: 0s - lo\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.6210\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.5333\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.4531\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.3754\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.3042\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.2314\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.1634\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.0979\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.0336\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.9698\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.9074\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.8432\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.7838\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.7276: \n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.6736\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.6190\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.5709\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.5247\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.4847\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.4475\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.4142\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.3861\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset.repeat(), epochs=EPOCHS, steps_per_epoch=steps_per_epoch, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKkD5M6eoSiN"
   },
   "source": [
    "## Generate text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JIPcXllKjkdr"
   },
   "source": [
    "### Restore the latest checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zk2WJ2-XjkGz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training/ckpt_30'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LycQ-ot_jjyu"
   },
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "71xa6jnYVrAN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (1, None, 256)            19968     \n",
      "_________________________________________________________________\n",
      "cu_dnngru_5 (CuDNNGRU)       (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (1, None, 78)             79950     \n",
      "=================================================================\n",
      "Total params: 4,038,222\n",
      "Trainable params: 4,038,222\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that generates the text with a prediction loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WvuwZBX5Ogfd"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    \n",
    "    #average number of characters in a Beyonce song \n",
    "    num_generate = 2139 \n",
    "\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    text_generated = []\n",
    "\n",
    "    # we want to keep this temperature low because we want the text that is generated to\n",
    "    #as accurately represent Beyonce lyrics as it can\n",
    "    temperature = 1.0 \n",
    " \n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.multinomial(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktovv0RFhrkn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beyonce] his myself, \"be pati? i trusted (oh) you dont need it i know i look so good tonight.\" god damn, god damn, god damn, god doing down ill be rocking on me, big ham getting bodied, getting bodied, getting bodied, getting bodied true im a very wife (oh) baby, you pasting it show daddy make stunkin took 45 minutes to get all dressed, upget around my coold youngr9 played outta telp me wway im not to help my hustle i can sen sand i moving through my system bress\"\"my jung on im graining and cause ar wwat ya fuckin a min than come and im sight the first time i save it in your love on top of me im a world-wide woman im a estall abore under these plicament now makes marriang or the walls of your money, if you actin to her cause now to you the world would revolve, without my friends i swear its a catch twenty-two cause the drummem spend wit when i amways will hep 2 stars cause i cant believe we made it its not worth the drama for a beautiful liar nos va dividir? (ha ha  quier so untair me (on to you, im on to you) me (on to you, im onith to my bags in my prockin chings crazy bigam tonight il me at never get it; drop down low and so doct , ill been sippin coming, keep me tighter than nike either way i dont wanna love you in no kind of damn i think im in lo destruyÃ£Â³ nunca llo nose wrong girlarios pirce dipat in love with a sagittarius see the pince a ms like when me and you, yeah, yeah, yeah) when you tere the light went that did just too good tough stopsupger insension you got no time, but we got patoknow on the coop i call it prooker than you yeah, i turneret, ell  in your bed (oh) you dont care (what goes something not a preacher but we can preater when you love me in the lights slights (larget of mallights on meen perfect, tu need to bad i tilk like this want is daggy, oh you gotta go to undress me  kiss me (never hustler, us lookin for da regles quith friends shot love all night feol, dont ask me feels like the bust you always right id matandined me all not even never backie (oh shet acalla) im sure of what to do its a catch it!) baby i will love you something thas i woke up like this, nigga please ap 2ll a\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"beyonce\")) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drunk in love we be all night  and im scared of being alone i cant sendin something to run, run, roll up rain all away, fall away\" bay the badies on the floor then you mix it up and call it creole [repeat 2x]  sees ang all you breakin its the side way i dont wanna wake up fronty stape with your ears  drown into your own all cause you wont let you go ill be your friend i will love you so deeply i gue shee vost aint got no ding on that wood, graining, gramping what ill move aint shining im aside foutin all my firstend (yea) im mile) its my showe you gonng time oout a chinch like a falont the love you like cause i close my eyes but im just too big homie the  need to ke up on it, im gon let you would real good wanna house if you dont know now you took your talk that i bought you! i wanna love you long time all of my waves se fun and my bass on your codie batter than through my syster man show him you the one that gives your all. youre the one that always callsice ©nough welkn moves amores eng mine toos a rock star?   its star bad boots on  pocial je to the lights you gonna lose my girls tricking with nike aright im gonna fuck your love was never true i got night, aint get it; drinking i got meet you down bitches (crown) bow, im scared of lonely and im smake smake sure a little with you it dont matter who you are it is so simple, a bet yes op a fuve wo love you bodied you forever, taking this a little too fallights the first exotions, i trusted (i like) take all of me i just wanna wake up from you (turn the lights on!) sweet dream or a beautiful nightmare either way i dont wanna wake up from you (turn the lights on!)  my guilty pleasurt, turn that cherry out, turn that cherry out turt your lies and type of this lifter do an old school dance up and good lovin? you and my wors hum boy, i moke everything i wonderity and no boy  you dont need it out  i dont know who you bet find the best e hustler...  theres no other man a holdrooooooooooo [beyonce]] esta vue voew for right  and you look me up and down and i came to make me call me baby  i cant den you thou, and make it rains youre this is for them a beyond kelliverstase wh\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"drunk in love\")) #can use a phrase here \n",
    "#this is one of her song lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tractoru³) youre my stock fighting to the lord so good to give my love to you  cuz everything i do is just for you  countin every secand til times i told you  in the djort back strath- im feeling im mustve just lost yo mind (you crazy) momemoneyes the aint no needer, thank) got me hoping youll page me right now, your kits you like its alriagh us so yands undress me  baby, let me know you never wanted me let this happen and it proves that you needs with you teach yourself when you lie dam at a click with your chick on your arms around me  it aint even im ald, coming about you, babe (oh) the one that you wanna touch it, baby? you dont want nobody excess the radio statching but i never every high we on that wood, gram home op them leave the way he fockin millox my love scared that we had espin sieper  yeah (let me whats in my bestor let me just say i dont wanna live without it 6 want it away... come right now  baby, love me lights  i see your face) you wanna touching my body? winning is by shit go died, we goust im feelin n-a-s-a-d-4-o ya turna-tio-pleach is around to carry all the signs, one at a hip hop star no more left, to chase melot he told me when i need. youre the only one i see. come on, baby, its you. youre the one that always flawless  its a line the block of me i think about it the left (mmmmmm) more just right  now thats how i like it, baby i dont wanna wake up from you (turn the lights on!) sweet dream or a beautiful nightmare either way i dont wanna wake uh huh  i said yes tonight i wanna make the slue love but im great at writing physical love letters im a fram, flawless my digapin they pray and pray for the emptase  if i dese ceione, ytar arm  im still around you right in my path, inferitt i got in the end thats what i wanna play in your dance ansown i think i need it i wanna be, i said you to believe its a catch twenty-two cause the cull the know? that someone touchin si you understand your marriage is that?  when im adone  [pre-chorus]  could it feel the sands, babla, hat a long time ago  im a star (ima aquarius), but even just cant stand smesbet when they save me right now now hangs in my gon\n"
     ]
    }
   ],
   "source": [
    "#using a word from a country song (not something you usually see in her songs) to see what the \n",
    "#model would produce\n",
    "print(generate_text(model, start_string=u\"tractor\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_generation.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
